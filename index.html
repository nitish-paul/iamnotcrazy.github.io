<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>The Research Post</title>

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400;600;700&family=Source+Serif+4:wght@400;500&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="style.css">
</head>

<body>

<header class="nav">
  <div class="nav-left">ThePost</div>
  <div class="nav-right">
    <span>Search</span>
    <span>•••</span>
  </div>
</header>

<main class="container">

  <!-- Hero -->
  <section class="hero">
    <h1>ThePost</h1>
    <p class="tagline">Research, distilled without noise</p>
  </section>

  <hr>

  <!-- Spotlight -->
  <section class="section">
    <h2>In The Spotlight</h2>

    <article class="story lead">
      <span class="meta">Dec 19 · Reinforcement Learning</span>
      <h3>Reinforcement Learning: A Clean Overview</h3>
      <p>
        Reinforcement learning studies how agents learn through interaction.
        Policies map states to actions, rewards guide improvement,
        and value functions estimate long-term return.
      </p>
    </article>
  </section>

  <!-- Latest Research -->
  <section class="section">
    <h2>Latest Research</h2>

    <article class="story">
      <span class="meta">arXiv · Quantum Computing</span>
      <h3>Quantum Flow Matching Without Known Initial States</h3>
      <p>
        Recent work attempts to bypass explicit density matrix initialization
        by sampling observable trajectories.
      </p>
    </article>

    <article class="story">
      <span class="meta">ICLR · Machine Learning</span>
      <h3>Why Flow Matching Competes With Diffusion</h3>
      <p>
        Deterministic training objectives remove stochastic sampling
        while preserving generative performance.
      </p>
    </article>
  </section>

  <!-- Quantum -->
  <section class="section">
    <h2>Quantum Computing</h2>

    <article class="story">
      <span class="meta">Concept</span>
      <h3>What Is a Lindbladian?</h3>
      <p>
        Lindblad operators govern open quantum system dynamics,
        extending Hamiltonian evolution to noisy environments.
      </p>
    </article>
  </section>

  <!-- ML -->
  <section class="section">
    <h2>Machine Learning</h2>

    <article class="story">
      <span class="meta">Overview</span>
      <h3>Policy Gradients in One Page</h3>
      <p>
        Policy gradients optimize expected reward directly
        by differentiating through action probabilities.
      </p>
    </article>
  </section>

</main>

<footer class="footer">
  <p>© 2025 The Research Post</p>
</footer>

</body>
</html>
